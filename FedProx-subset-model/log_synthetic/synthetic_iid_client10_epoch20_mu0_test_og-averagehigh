Arguments:
	       batch_size : 10
	clients_per_round : 5
	          dataset : synthetic_1_1
	     drop_percent : 0.7
	       eval_every : 1
	    learning_rate : 0.01
	            model : mclr
	     model_params : (10,)
	               mu : 0
	       num_epochs : 20
	        num_iters : 1
	       num_rounds : 200
	        optimizer : fedavg
	             seed : 0
Using Federated avg to Train

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/1.50k flops)
  dense/kernel/Regularizer/l2_regularizer (1/900 flops)
    dense/kernel/Regularizer/l2_regularizer/L2Loss (899/899 flops)
  dense/kernel/Initializer/random_uniform (300/601 flops)
    dense/kernel/Initializer/random_uniform/mul (300/300 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
Parsing Inputs...

=========================Options=============================
-max_depth                  10000
-min_bytes                  0
-min_peak_bytes             0
-min_residual_bytes         0
-min_output_bytes           0
-min_micros                 0
-min_accelerator_micros     0
-min_cpu_micros             0
-min_params                 0
-min_float_ops              1
-min_occurrence             0
-step                       -1
-order_by                   float_ops
-account_type_regexes       .*
-start_name_regexes         .*
-trim_name_regexes          
-show_name_regexes          .*
-hide_name_regexes          
-account_displayed_op_only  true
-select                     float_ops
-output                     stdout:

==================Model Analysis Report======================

Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
flops: Number of float operations. Note: Please read the implementation for the math behind it.

Profile:
node name | # float_ops
_TFProfRoot (--/3.00k flops)
  dense/kernel/Regularizer/l2_regularizer (1/1.80k flops)
    dense/kernel/Regularizer/l2_regularizer/L2Loss (1.80k/1.80k flops)
  dense/kernel/Initializer/random_uniform (600/1.20k flops)
    dense/kernel/Initializer/random_uniform/mul (600/600 flops)
    dense/kernel/Initializer/random_uniform/sub (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/Neg (1/1 flops)
  gradients/sparse_softmax_cross_entropy_loss/value_grad/mul (1/1 flops)
  sparse_softmax_cross_entropy_loss/num_present/Equal (1/1 flops)

======================End of Report==========================
k 1
k 8
k 2
k 24
k 13
k 8
k 3
k 26
k 28
k 27
k 1
k 12
k 17
k 17
k 10
10 Clients in Total
optionss {'optimizer': 'fedavg', 'dataset': 'synthetic_1_1', 'model': 'mclr', 'num_rounds': 200, 'eval_every': 1, 'clients_per_round': 5, 'batch_size': 10, 'num_epochs': 20, 'num_iters': 1, 'learning_rate': 0.01, 'mu': 0, 'seed': 0, 'drop_percent': 0.7, 'model_params': (10,)}
Training with 5 workers ---
At round 0 accuracy: 0.03505535055350553
At round 0 training accuracy: 0.0334375
At round 0 training loss: 6.838641936232646
(60, 10)
At round 1 accuracy: 0.06457564575645756
At round 1 training accuracy: 0.0590625
At round 1 training loss: 5.306359540877553
(60, 10)
At round 2 accuracy: 0.06088560885608856
At round 2 training accuracy: 0.057604166666666665
At round 2 training loss: 5.026775548607111
(60, 10)
At round 3 accuracy: 0.44649446494464945
At round 3 training accuracy: 0.48385416666666664
At round 3 training loss: 1.4475860390687982
(60, 10)
At round 4 accuracy: 0.45295202952029523
At round 4 training accuracy: 0.4715625
At round 4 training loss: 1.4665630991384386
(60, 10)
At round 5 accuracy: 0.507380073800738
At round 5 training accuracy: 0.5423958333333333
At round 5 training loss: 1.3435996552867193
(60, 10)
At round 6 accuracy: 0.5055350553505535
At round 6 training accuracy: 0.4892708333333333
At round 6 training loss: 1.583530778090159
(60, 10)
At round 7 accuracy: 0.44280442804428044
At round 7 training accuracy: 0.4334375
At round 7 training loss: 1.6764102847346416
(60, 10)
At round 8 accuracy: 0.5193726937269373
At round 8 training accuracy: 0.5084375
At round 8 training loss: 1.3925365295776282
(60, 10)
At round 9 accuracy: 0.5027675276752768
At round 9 training accuracy: 0.4922916666666667
At round 9 training loss: 1.4679355796954283
(60, 10)
At round 10 accuracy: 0.5608856088560885
At round 10 training accuracy: 0.5884375
At round 10 training loss: 1.385052322965736
(60, 10)
At round 11 accuracy: 0.5415129151291513
At round 11 training accuracy: 0.5796875
At round 11 training loss: 1.30782786948781
(60, 10)
At round 12 accuracy: 0.5525830258302583
At round 12 training accuracy: 0.5886458333333333
At round 12 training loss: 1.221589320814237
(60, 10)
At round 13 accuracy: 0.559040590405904
At round 13 training accuracy: 0.5991666666666666
At round 13 training loss: 1.484585270602256
(60, 10)
At round 14 accuracy: 0.5784132841328413
At round 14 training accuracy: 0.6234375
At round 14 training loss: 1.2995429140639803
(60, 10)
At round 15 accuracy: 0.5055350553505535
At round 15 training accuracy: 0.5014583333333333
At round 15 training loss: 1.6063846248124416
(60, 10)
At round 16 accuracy: 0.47232472324723246
At round 16 training accuracy: 0.47302083333333333
At round 16 training loss: 1.5769698613105962
(60, 10)
At round 17 accuracy: 0.522140221402214
At round 17 training accuracy: 0.5116666666666667
At round 17 training loss: 1.5357245845844347
(60, 10)
At round 18 accuracy: 0.466789667896679
At round 18 training accuracy: 0.4625
At round 18 training loss: 1.6421722561664258
(60, 10)
At round 19 accuracy: 0.4280442804428044
At round 19 training accuracy: 0.4284375
At round 19 training loss: 1.8175146157527342
(60, 10)
At round 20 accuracy: 0.47601476014760147
At round 20 training accuracy: 0.4769791666666667
At round 20 training loss: 1.5545555138587952
(60, 10)
At round 21 accuracy: 0.5156826568265682
At round 21 training accuracy: 0.5113541666666667
At round 21 training loss: 1.3764528975076973
(60, 10)
At round 22 accuracy: 0.4455719557195572
At round 22 training accuracy: 0.4372916666666667
At round 22 training loss: 1.8502991637137407
(60, 10)
At round 23 accuracy: 0.48523985239852396
At round 23 training accuracy: 0.47239583333333335
At round 23 training loss: 1.5665203167676616
(60, 10)
At round 24 accuracy: 0.6374538745387454
At round 24 training accuracy: 0.6680208333333333
At round 24 training loss: 1.0401492967301358
(60, 10)
At round 25 accuracy: 0.5894833948339483
At round 25 training accuracy: 0.6028125
At round 25 training loss: 1.3016392589872703
(60, 10)
At round 26 accuracy: 0.5959409594095941
At round 26 training accuracy: 0.628125
At round 26 training loss: 1.200584535902987
(60, 10)
At round 27 accuracy: 0.5959409594095941
At round 27 training accuracy: 0.6310416666666666
At round 27 training loss: 1.2238507114785413
(60, 10)
At round 28 accuracy: 0.5977859778597786
At round 28 training accuracy: 0.5980208333333333
At round 28 training loss: 1.387697913995944
(60, 10)
At round 29 accuracy: 0.584870848708487
At round 29 training accuracy: 0.6044791666666667
At round 29 training loss: 1.3308326374570607
(60, 10)
At round 30 accuracy: 0.5904059040590406
At round 30 training accuracy: 0.6082291666666667
At round 30 training loss: 1.4499423316586764
(60, 10)
At round 31 accuracy: 0.5433579335793358
At round 31 training accuracy: 0.5775
At round 31 training loss: 1.5173493660303454
(60, 10)
At round 32 accuracy: 0.6005535055350554
At round 32 training accuracy: 0.6360416666666666
At round 32 training loss: 1.1421730201505125
(60, 10)
At round 33 accuracy: 0.6079335793357934
At round 33 training accuracy: 0.6338541666666667
At round 33 training loss: 1.3389407668930169
(60, 10)
At round 34 accuracy: 0.5885608856088561
At round 34 training accuracy: 0.6260416666666667
At round 34 training loss: 1.2545314757448311
(60, 10)
At round 35 accuracy: 0.5821033210332104
At round 35 training accuracy: 0.5827083333333334
At round 35 training loss: 1.4945515953889117
(60, 10)
At round 36 accuracy: 0.5239852398523985
At round 36 training accuracy: 0.5158333333333334
At round 36 training loss: 1.5487781976722181
(60, 10)
At round 37 accuracy: 0.6014760147601476
At round 37 training accuracy: 0.6372916666666667
At round 37 training loss: 1.4254510796178754
(60, 10)
At round 38 accuracy: 0.5821033210332104
At round 38 training accuracy: 0.6077083333333333
At round 38 training loss: 1.5681752934617301
(60, 10)
At round 39 accuracy: 0.6097785977859779
At round 39 training accuracy: 0.63625
At round 39 training loss: 1.4421473724006986
(60, 10)
At round 40 accuracy: 0.5839483394833949
At round 40 training accuracy: 0.588125
At round 40 training loss: 1.9112967499376585
(60, 10)
At round 41 accuracy: 0.5987084870848709
At round 41 training accuracy: 0.6345833333333334
At round 41 training loss: 1.5010237368064312
(60, 10)
At round 42 accuracy: 0.6079335793357934
At round 42 training accuracy: 0.6416666666666667
At round 42 training loss: 1.2079181388796618
(60, 10)
At round 43 accuracy: 0.6245387453874539
At round 43 training accuracy: 0.6517708333333333
At round 43 training loss: 1.20594725331602
(60, 10)
At round 44 accuracy: 0.6107011070110702
At round 44 training accuracy: 0.6355208333333333
At round 44 training loss: 1.4165459137161573
(60, 10)
At round 45 accuracy: 0.6116236162361623
At round 45 training accuracy: 0.6378125
At round 45 training loss: 1.2794697437171514
(60, 10)
At round 46 accuracy: 0.6042435424354243
At round 46 training accuracy: 0.6345833333333334
At round 46 training loss: 1.5356926878883193
(60, 10)
At round 47 accuracy: 0.5977859778597786
At round 47 training accuracy: 0.6246875
At round 47 training loss: 1.8544051285088061
(60, 10)
At round 48 accuracy: 0.5977859778597786
At round 48 training accuracy: 0.5972916666666667
At round 48 training loss: 1.3622688235435634
(60, 10)
At round 49 accuracy: 0.48154981549815495
At round 49 training accuracy: 0.4744791666666667
At round 49 training loss: 2.1360246896681687
(60, 10)
At round 50 accuracy: 0.6005535055350554
At round 50 training accuracy: 0.6170833333333333
At round 50 training loss: 1.8550384086494645
(60, 10)
At round 51 accuracy: 0.6023985239852399
At round 51 training accuracy: 0.6102083333333334
At round 51 training loss: 1.4945662307242553
(60, 10)
At round 52 accuracy: 0.6319188191881919
At round 52 training accuracy: 0.6629166666666667
At round 52 training loss: 1.242350531720246
(60, 10)
At round 53 accuracy: 0.5857933579335793
At round 53 training accuracy: 0.6184375
At round 53 training loss: 1.6971834235234806
(60, 10)
At round 54 accuracy: 0.5535055350553506
At round 54 training accuracy: 0.57
At round 54 training loss: 1.4609559310600162
(60, 10)
At round 55 accuracy: 0.6079335793357934
At round 55 training accuracy: 0.6439583333333333
At round 55 training loss: 1.139180066700404
(60, 10)
At round 56 accuracy: 0.6023985239852399
At round 56 training accuracy: 0.6341666666666667
At round 56 training loss: 1.612397531059881
(60, 10)
At round 57 accuracy: 0.6023985239852399
At round 57 training accuracy: 0.619375
At round 57 training loss: 1.3146663135786851
(60, 10)
At round 58 accuracy: 0.6060885608856088
At round 58 training accuracy: 0.6417708333333333
At round 58 training loss: 1.409559913352132
(60, 10)
At round 59 accuracy: 0.6162361623616236
At round 59 training accuracy: 0.6378125
At round 59 training loss: 1.246039202149647
(60, 10)
At round 60 accuracy: 0.6245387453874539
At round 60 training accuracy: 0.6408333333333334
At round 60 training loss: 1.3856431704262893
(60, 10)
At round 61 accuracy: 0.6254612546125461
At round 61 training accuracy: 0.6589583333333333
At round 61 training loss: 1.3796728822294002
(60, 10)
At round 62 accuracy: 0.6143911439114391
At round 62 training accuracy: 0.6428125
At round 62 training loss: 1.21341991336861
(60, 10)
At round 63 accuracy: 0.6282287822878229
At round 63 training accuracy: 0.65125
At round 63 training loss: 1.2246678661213566
(60, 10)
At round 64 accuracy: 0.5950184501845018
At round 64 training accuracy: 0.5979166666666667
At round 64 training loss: 1.5606000218198945
(60, 10)
At round 65 accuracy: 0.5931734317343174
At round 65 training accuracy: 0.6004166666666667
At round 65 training loss: 1.5722859801600377
(60, 10)
At round 66 accuracy: 0.6125461254612546
At round 66 training accuracy: 0.6285416666666667
At round 66 training loss: 1.4910672998273125
(60, 10)
At round 67 accuracy: 0.6097785977859779
At round 67 training accuracy: 0.6184375
At round 67 training loss: 1.4203570358200037
(60, 10)
At round 68 accuracy: 0.6162361623616236
At round 68 training accuracy: 0.6366666666666667
At round 68 training loss: 1.4057385675589709
(60, 10)
At round 69 accuracy: 0.6429889298892989
At round 69 training accuracy: 0.6661458333333333
At round 69 training loss: 1.1328832986392081
(60, 10)
At round 70 accuracy: 0.6171586715867159
At round 70 training accuracy: 0.6438541666666666
At round 70 training loss: 1.4219134264284123
(60, 10)
At round 71 accuracy: 0.577490774907749
At round 71 training accuracy: 0.5947916666666667
At round 71 training loss: 1.7294658510635297
(60, 10)
At round 72 accuracy: 0.6116236162361623
At round 72 training accuracy: 0.641875
At round 72 training loss: 1.6242113777219007
(60, 10)
At round 73 accuracy: 0.6097785977859779
At round 73 training accuracy: 0.6219791666666666
At round 73 training loss: 1.6385454640475412
(60, 10)
At round 74 accuracy: 0.6079335793357934
At round 74 training accuracy: 0.6146875
At round 74 training loss: 1.1259554419200868
(60, 10)
At round 75 accuracy: 0.6180811808118081
At round 75 training accuracy: 0.6378125
At round 75 training loss: 1.388111855185222
(60, 10)
At round 76 accuracy: 0.6254612546125461
At round 76 training accuracy: 0.6359375
At round 76 training loss: 1.2135355035618218
(60, 10)
At round 77 accuracy: 0.6125461254612546
At round 77 training accuracy: 0.6276041666666666
At round 77 training loss: 1.4142274705391416
(60, 10)
At round 78 accuracy: 0.6079335793357934
At round 78 training accuracy: 0.6101041666666667
At round 78 training loss: 1.5290130490600131
(60, 10)
At round 79 accuracy: 0.6226937269372693
At round 79 training accuracy: 0.6523958333333333
At round 79 training loss: 1.455444857169253
(60, 10)
At round 80 accuracy: 0.6116236162361623
At round 80 training accuracy: 0.6411458333333333
At round 80 training loss: 1.6411242220985394
(60, 10)
At round 81 accuracy: 0.6356088560885609
At round 81 training accuracy: 0.660625
At round 81 training loss: 1.245273445037504
(60, 10)
At round 82 accuracy: 0.6273062730627307
At round 82 training accuracy: 0.655625
At round 82 training loss: 1.464928073277697
(60, 10)
At round 83 accuracy: 0.6263837638376384
At round 83 training accuracy: 0.6513541666666667
At round 83 training loss: 1.0915991462022065
(60, 10)
At round 84 accuracy: 0.6263837638376384
At round 84 training accuracy: 0.6540625
At round 84 training loss: 1.421809547903637
(60, 10)
At round 85 accuracy: 0.6402214022140221
At round 85 training accuracy: 0.6623958333333333
At round 85 training loss: 1.2449890690296888
(60, 10)
At round 86 accuracy: 0.6429889298892989
At round 86 training accuracy: 0.6589583333333333
At round 86 training loss: 1.1980005771891835
(60, 10)
At round 87 accuracy: 0.6402214022140221
At round 87 training accuracy: 0.6648958333333334
At round 87 training loss: 1.444071762257566
(60, 10)
At round 88 accuracy: 0.6236162361623616
At round 88 training accuracy: 0.6344791666666667
At round 88 training loss: 1.79408459866109
(60, 10)
At round 89 accuracy: 0.6365313653136532
At round 89 training accuracy: 0.6441666666666667
At round 89 training loss: 1.4493217347329483
(60, 10)
At round 90 accuracy: 0.6402214022140221
At round 90 training accuracy: 0.6482291666666666
At round 90 training loss: 1.2076431578001938
(60, 10)
At round 91 accuracy: 0.6466789667896679
At round 91 training accuracy: 0.6616666666666666
At round 91 training loss: 1.1930163367519466
(60, 10)
At round 92 accuracy: 0.6060885608856088
At round 92 training accuracy: 0.5875
At round 92 training loss: 1.9227554270842424
(60, 10)
At round 93 accuracy: 0.5876383763837638
At round 93 training accuracy: 0.5729166666666666
At round 93 training loss: 1.4214603773045624
(60, 10)
At round 94 accuracy: 0.5654981549815498
At round 94 training accuracy: 0.5395833333333333
At round 94 training loss: 1.767734376952673
(60, 10)
At round 95 accuracy: 0.5608856088560885
At round 95 training accuracy: 0.5478125
At round 95 training loss: 1.7678171032853425
(60, 10)
At round 96 accuracy: 0.6457564575645757
At round 96 training accuracy: 0.669375
At round 96 training loss: 1.400387144118237
(60, 10)
At round 97 accuracy: 0.6236162361623616
At round 97 training accuracy: 0.6333333333333333
At round 97 training loss: 1.672636500261724
(60, 10)
At round 98 accuracy: 0.6374538745387454
At round 98 training accuracy: 0.6564583333333334
At round 98 training loss: 1.4446541368216277
(60, 10)
At round 99 accuracy: 0.6365313653136532
At round 99 training accuracy: 0.6485416666666667
At round 99 training loss: 1.462803573696874
(60, 10)
At round 100 accuracy: 0.6079335793357934
At round 100 training accuracy: 0.5972916666666667
At round 100 training loss: 1.3325604864411678
(60, 10)
At round 101 accuracy: 0.5987084870848709
At round 101 training accuracy: 0.58125
At round 101 training loss: 1.6343193675453465
(60, 10)
At round 102 accuracy: 0.5922509225092251
At round 102 training accuracy: 0.5798958333333334
At round 102 training loss: 1.6561476432469984
(60, 10)
At round 103 accuracy: 0.525830258302583
At round 103 training accuracy: 0.510625
At round 103 training loss: 1.5485946296869466
(60, 10)
At round 104 accuracy: 0.6383763837638377
At round 104 training accuracy: 0.66375
At round 104 training loss: 1.1856113502418157
(60, 10)
At round 105 accuracy: 0.6236162361623616
At round 105 training accuracy: 0.6265625
At round 105 training loss: 1.272899352024154
(60, 10)
At round 106 accuracy: 0.6605166051660517
At round 106 training accuracy: 0.6703125
At round 106 training loss: 1.195192764479046
(60, 10)
At round 107 accuracy: 0.6171586715867159
At round 107 training accuracy: 0.636875
At round 107 training loss: 1.5036919352489835
(60, 10)
At round 108 accuracy: 0.6402214022140221
At round 108 training accuracy: 0.6563541666666667
At round 108 training loss: 1.192463780924057
(60, 10)
At round 109 accuracy: 0.6392988929889298
At round 109 training accuracy: 0.6611458333333333
At round 109 training loss: 1.4578480382729322
(60, 10)
At round 110 accuracy: 0.6162361623616236
At round 110 training accuracy: 0.6444791666666667
At round 110 training loss: 1.6813744729850442
(60, 10)
At round 111 accuracy: 0.6540590405904059
At round 111 training accuracy: 0.6728125
At round 111 training loss: 1.2017651190826049
(60, 10)
At round 112 accuracy: 0.6559040590405905
At round 112 training accuracy: 0.6611458333333333
At round 112 training loss: 1.2194303844651828
(60, 10)
At round 113 accuracy: 0.6374538745387454
At round 113 training accuracy: 0.6613541666666667
At round 113 training loss: 1.201192332985035
(60, 10)
At round 114 accuracy: 0.5996309963099631
At round 114 training accuracy: 0.616875
At round 114 training loss: 1.7371287278551608
(60, 10)
At round 115 accuracy: 0.6226937269372693
At round 115 training accuracy: 0.6540625
At round 115 training loss: 1.069726899381106
(60, 10)
At round 116 accuracy: 0.6208487084870848
At round 116 training accuracy: 0.6378125
At round 116 training loss: 1.3215566644382974
(60, 10)
At round 117 accuracy: 0.6485239852398524
At round 117 training accuracy: 0.6770833333333334
At round 117 training loss: 1.3869093035378803
(60, 10)
At round 118 accuracy: 0.6420664206642066
At round 118 training accuracy: 0.6534375
At round 118 training loss: 1.2052782055807378
(60, 10)
At round 119 accuracy: 0.6678966789667896
At round 119 training accuracy: 0.6882291666666667
At round 119 training loss: 1.1469523012513916
(60, 10)
At round 120 accuracy: 0.6503690036900369
At round 120 training accuracy: 0.6866666666666666
At round 120 training loss: 1.1244072818135222
(60, 10)
At round 121 accuracy: 0.6512915129151291
At round 121 training accuracy: 0.6735416666666667
At round 121 training loss: 1.1801147581124678
(60, 10)
At round 122 accuracy: 0.6088560885608856
At round 122 training accuracy: 0.613125
At round 122 training loss: 1.7314563856894771
(60, 10)
At round 123 accuracy: 0.6392988929889298
At round 123 training accuracy: 0.6489583333333333
At round 123 training loss: 1.073518733990689
(60, 10)
At round 124 accuracy: 0.6466789667896679
At round 124 training accuracy: 0.6515625
At round 124 training loss: 1.1814783918081473
(60, 10)
At round 125 accuracy: 0.6512915129151291
At round 125 training accuracy: 0.6652083333333333
At round 125 training loss: 1.1826709897629917
(60, 10)
At round 126 accuracy: 0.5922509225092251
At round 126 training accuracy: 0.611875
At round 126 training loss: 1.606790088325118
(60, 10)
At round 127 accuracy: 0.6088560885608856
At round 127 training accuracy: 0.6221875
At round 127 training loss: 1.2968949236472447
(60, 10)
At round 128 accuracy: 0.6291512915129152
At round 128 training accuracy: 0.6413541666666667
At round 128 training loss: 1.5386091247138878
(60, 10)
At round 129 accuracy: 0.6540590405904059
At round 129 training accuracy: 0.6759375
At round 129 training loss: 1.4725171830536177
(60, 10)
At round 130 accuracy: 0.6789667896678967
At round 130 training accuracy: 0.69625
At round 130 training loss: 1.1588622796318184
(60, 10)
At round 131 accuracy: 0.6549815498154982
At round 131 training accuracy: 0.6736458333333334
At round 131 training loss: 1.0507026330350588
(60, 10)
At round 132 accuracy: 0.6780442804428044
At round 132 training accuracy: 0.6888541666666667
At round 132 training loss: 1.1621471089031548
(60, 10)
At round 133 accuracy: 0.6383763837638377
At round 133 training accuracy: 0.6619791666666667
At round 133 training loss: 1.833574482832725
(60, 10)
At round 134 accuracy: 0.6577490774907749
At round 134 training accuracy: 0.6794791666666666
At round 134 training loss: 1.2779367170203477
(60, 10)
At round 135 accuracy: 0.6512915129151291
At round 135 training accuracy: 0.6846875
At round 135 training loss: 1.4180014450615273
(60, 10)
At round 136 accuracy: 0.6346863468634686
At round 136 training accuracy: 0.6430208333333334
At round 136 training loss: 1.4993695181577156
(60, 10)
At round 137 accuracy: 0.6485239852398524
At round 137 training accuracy: 0.673125
At round 137 training loss: 1.4856772985775024
(60, 10)
At round 138 accuracy: 0.6494464944649446
At round 138 training accuracy: 0.6584375
At round 138 training loss: 1.2319204230741403
(60, 10)
At round 139 accuracy: 0.6494464944649446
At round 139 training accuracy: 0.6760416666666667
At round 139 training loss: 1.2052878367479813
(60, 10)
At round 140 accuracy: 0.6577490774907749
At round 140 training accuracy: 0.6765625
At round 140 training loss: 1.21820794298624
(60, 10)
At round 141 accuracy: 0.6439114391143912
At round 141 training accuracy: 0.6657291666666667
At round 141 training loss: 1.4979296433879064
(60, 10)
At round 142 accuracy: 0.6448339483394834
At round 142 training accuracy: 0.6573958333333333
At round 142 training loss: 1.51443118475688
(60, 10)
At round 143 accuracy: 0.6291512915129152
At round 143 training accuracy: 0.6345833333333334
At round 143 training loss: 1.4767911143891979
(60, 10)
At round 144 accuracy: 0.6328413284132841
At round 144 training accuracy: 0.6330208333333334
At round 144 training loss: 1.3869652158673853
(60, 10)
At round 145 accuracy: 0.6540590405904059
At round 145 training accuracy: 0.6666666666666666
At round 145 training loss: 1.2166198222183933
(60, 10)
At round 146 accuracy: 0.6669741697416974
At round 146 training accuracy: 0.6764583333333334
At round 146 training loss: 1.190151185222591
(60, 10)
At round 147 accuracy: 0.6568265682656826
At round 147 training accuracy: 0.680625
At round 147 training loss: 1.1993001915398054
(60, 10)
At round 148 accuracy: 0.6605166051660517
At round 148 training accuracy: 0.6821875
At round 148 training loss: 1.178121795897993
(60, 10)
At round 149 accuracy: 0.6383763837638377
At round 149 training accuracy: 0.6573958333333333
At round 149 training loss: 1.5529243086976932
(60, 10)
At round 150 accuracy: 0.6420664206642066
At round 150 training accuracy: 0.6746875
At round 150 training loss: 1.4611095825598264
(60, 10)
At round 151 accuracy: 0.6217712177121771
At round 151 training accuracy: 0.6309375
At round 151 training loss: 1.9303837084397673
(60, 10)
At round 152 accuracy: 0.6485239852398524
At round 152 training accuracy: 0.6704166666666667
At round 152 training loss: 1.5251986302466443
(60, 10)
At round 153 accuracy: 0.6226937269372693
At round 153 training accuracy: 0.6578125
At round 153 training loss: 1.7003380867217979
(60, 10)
At round 154 accuracy: 0.6319188191881919
At round 154 training accuracy: 0.6292708333333333
At round 154 training loss: 1.2925882444394907
(60, 10)
At round 155 accuracy: 0.6356088560885609
At round 155 training accuracy: 0.6541666666666667
At round 155 training loss: 1.4701040473397977
(60, 10)
At round 156 accuracy: 0.6586715867158671
At round 156 training accuracy: 0.6795833333333333
At round 156 training loss: 1.2013057548642003
(60, 10)
At round 157 accuracy: 0.6503690036900369
At round 157 training accuracy: 0.6710416666666666
At round 157 training loss: 1.523900691336021
(60, 10)
At round 158 accuracy: 0.6605166051660517
At round 158 training accuracy: 0.6846875
At round 158 training loss: 1.1984462585595126
(60, 10)
At round 159 accuracy: 0.6402214022140221
At round 159 training accuracy: 0.6707291666666667
At round 159 training loss: 1.502985423679153
(60, 10)
At round 160 accuracy: 0.6411439114391144
At round 160 training accuracy: 0.67125
At round 160 training loss: 1.5076949045217285
(60, 10)
At round 161 accuracy: 0.6531365313653137
At round 161 training accuracy: 0.6732291666666667
At round 161 training loss: 1.4967069618791962
(60, 10)
At round 162 accuracy: 0.6512915129151291
At round 162 training accuracy: 0.6767708333333333
At round 162 training loss: 1.5040893618917714
(60, 10)
At round 163 accuracy: 0.6374538745387454
At round 163 training accuracy: 0.666875
At round 163 training loss: 1.4900388331261154
(60, 10)
At round 164 accuracy: 0.6171586715867159
At round 164 training accuracy: 0.6433333333333333
At round 164 training loss: 1.5165196282497102
(60, 10)
At round 165 accuracy: 0.6226937269372693
At round 165 training accuracy: 0.6467708333333333
At round 165 training loss: 1.594796579737061
(60, 10)
At round 166 accuracy: 0.5830258302583026
At round 166 training accuracy: 0.6017708333333334
At round 166 training loss: 1.437874642337362
(60, 10)
At round 167 accuracy: 0.6337638376383764
At round 167 training accuracy: 0.6578125
At round 167 training loss: 1.509142370192955
(60, 10)
At round 168 accuracy: 0.6309963099630996
At round 168 training accuracy: 0.6575
At round 168 training loss: 1.4844297662785781
(60, 10)
At round 169 accuracy: 0.6549815498154982
At round 169 training accuracy: 0.6889583333333333
At round 169 training loss: 1.4558591818390414
(60, 10)
At round 170 accuracy: 0.6577490774907749
At round 170 training accuracy: 0.6623958333333333
At round 170 training loss: 1.2577546944760252
(60, 10)
At round 171 accuracy: 0.6226937269372693
At round 171 training accuracy: 0.6305208333333333
At round 171 training loss: 1.6445806086466959
(60, 10)
At round 172 accuracy: 0.5913284132841329
At round 172 training accuracy: 0.6040625
At round 172 training loss: 2.0417793339801333
(60, 10)
At round 173 accuracy: 0.6660516605166051
At round 173 training accuracy: 0.6813541666666667
At round 173 training loss: 1.2263749196120382
(60, 10)
At round 174 accuracy: 0.6199261992619927
At round 174 training accuracy: 0.610625
At round 174 training loss: 1.2026242337717363
(60, 10)
At round 175 accuracy: 0.683579335793358
At round 175 training accuracy: 0.6879166666666666
At round 175 training loss: 1.2051185944241782
(60, 10)
At round 176 accuracy: 0.6457564575645757
At round 176 training accuracy: 0.6722916666666666
At round 176 training loss: 1.489818646744825
(60, 10)
At round 177 accuracy: 0.5996309963099631
At round 177 training accuracy: 0.61
At round 177 training loss: 2.013201195883254
(60, 10)
At round 178 accuracy: 0.6162361623616236
At round 178 training accuracy: 0.6439583333333333
At round 178 training loss: 1.7603398968900243
(60, 10)
At round 179 accuracy: 0.6051660516605166
At round 179 training accuracy: 0.5944791666666667
At round 179 training loss: 1.6418786197272128
(60, 10)
At round 180 accuracy: 0.6706642066420664
At round 180 training accuracy: 0.6988541666666667
At round 180 training loss: 1.1610595893797775
(60, 10)
At round 181 accuracy: 0.6374538745387454
At round 181 training accuracy: 0.6613541666666667
At round 181 training loss: 1.4898894054823903
(60, 10)
At round 182 accuracy: 0.6771217712177122
At round 182 training accuracy: 0.6972916666666666
At round 182 training loss: 1.1701767109179249
(60, 10)
At round 183 accuracy: 0.6577490774907749
At round 183 training accuracy: 0.6770833333333334
At round 183 training loss: 1.220487291427368
(60, 10)
At round 184 accuracy: 0.6411439114391144
At round 184 training accuracy: 0.6620833333333334
At round 184 training loss: 1.5909023247907559
(60, 10)
At round 185 accuracy: 0.6420664206642066
At round 185 training accuracy: 0.6785416666666667
At round 185 training loss: 1.5125787201834222
(60, 10)
At round 186 accuracy: 0.6457564575645757
At round 186 training accuracy: 0.6705208333333333
At round 186 training loss: 1.5532404259235288
(60, 10)
At round 187 accuracy: 0.6420664206642066
At round 187 training accuracy: 0.678125
At round 187 training loss: 1.5166069809782008
(60, 10)
At round 188 accuracy: 0.6466789667896679
At round 188 training accuracy: 0.6719791666666667
At round 188 training loss: 1.5903148413263262
(60, 10)
At round 189 accuracy: 0.6383763837638377
At round 189 training accuracy: 0.6672916666666666
At round 189 training loss: 1.5756776836335968
(60, 10)
At round 190 accuracy: 0.6337638376383764
At round 190 training accuracy: 0.6360416666666666
At round 190 training loss: 1.3177466330479364
(60, 10)
At round 191 accuracy: 0.6512915129151291
At round 191 training accuracy: 0.655625
At round 191 training loss: 1.2672762684741368
(60, 10)
At round 192 accuracy: 0.6153136531365314
At round 192 training accuracy: 0.605625
At round 192 training loss: 1.4002559038856999
(60, 10)
At round 193 accuracy: 0.6743542435424354
At round 193 training accuracy: 0.7023958333333333
At round 193 training loss: 1.1631076326686889
(60, 10)
At round 194 accuracy: 0.6448339483394834
At round 194 training accuracy: 0.6814583333333334
At round 194 training loss: 1.5195390459087987
(60, 10)
At round 195 accuracy: 0.6300738007380073
At round 195 training accuracy: 0.6432291666666666
At round 195 training loss: 1.5952191114487748
(60, 10)
At round 196 accuracy: 0.6208487084870848
At round 196 training accuracy: 0.6320833333333333
At round 196 training loss: 1.5773763020415208
(60, 10)
At round 197 accuracy: 0.6402214022140221
At round 197 training accuracy: 0.6467708333333333
At round 197 training loss: 1.2948959104406337
(60, 10)
At round 198 accuracy: 0.6678966789667896
At round 198 training accuracy: 0.683125
At round 198 training loss: 1.2036446187521022
(60, 10)
At round 199 accuracy: 0.665129151291513
At round 199 training accuracy: 0.6894791666666666
At round 199 training loss: 1.2186666721016324
(60, 10)
At round 200 accuracy: 0.6448339483394834
At round 200 training accuracy: 0.67375
